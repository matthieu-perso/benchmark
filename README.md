# MultiTask Personalization Assessment (MPTA)

This repository accompanies the paper submitted to EMNLP 2025, focusing on a unified benchmark for evaluating large language models (LLMs) across multiple tasks. The benchmark is designed to be modular, extensible, and maintainable, facilitating a comprehensive evaluation of LLMs on tasks that were previously considered separately.

## YAML Configuration

We map the datasets to a YAML configuration file. This ensures that we find the structure of the dataset and the exact columns that we need to extract.

